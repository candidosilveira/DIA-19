{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set I\n",
    "\n",
    "Nessa lista de exercícios testaremos comandos básicos para carregar e manipular um dataset em Python. O dataset que usaremos ao longo do curso são os dados do ENEM de 2017. Os dados estão disponíveis gratuitamente no site do INEP:\n",
    "\n",
    "http://download.inep.gov.br/microdados/microdados_enem2017.zip\n",
    "\n",
    "O primeiro passo é baixar os dados. No site do INEP você poderá encontrar vários outros datasets, incluindo microdados do ENEM desde 2004. \n",
    "\n",
    "\n",
    "## **Atividade 1**: Baixe os dados do ENEM, e salve na pasta `dados`. *Cuidado:* os dados são grandes ($\\approx$1GB).\n",
    "\n",
    "Agora vamos manipular os dados usando um pacote chamado `pandas`. Uma introdução ao `pandas` pode ser encontrada aqui:\n",
    "\n",
    "* https://towardsdatascience.com/pandas-dataframe-a-lightweight-intro-680e3a212b96\n",
    "* https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # biblioteca para manipular dados em dataframes\n",
    "import numpy as np   # biblioteca para manipulação numérica em python\n",
    "import matplotlib.pyplot as plt # biblioteca para gerar gráficos em python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O póximo comando carrega os dados. Ajuste a variável `filepath` para ser a pasta dos dados no seu computador. Os dados serão armazenados em um objeto em `pandas` chamado o `dataframe`, denotado aqui por `df`. \n",
    "\n",
    "Os dados são carregados usando o comando `pd.read_csv`. Note que vamos carregar apenas as 500k primeiras linhas dos dados (i.e., dados de apenas 500k estudantes). Delete o parâmetro `nrows` em `pd.read_csv` para carregar os dados inteiros. Note que isso pode demorar muito dependendo do seu computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>CO_MUNICIPIO_RESIDENCIA</th>\n",
       "      <th>NO_MUNICIPIO_RESIDENCIA</th>\n",
       "      <th>CO_UF_RESIDENCIA</th>\n",
       "      <th>SG_UF_RESIDENCIA</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>...</th>\n",
       "      <th>Q018</th>\n",
       "      <th>Q019</th>\n",
       "      <th>Q020</th>\n",
       "      <th>Q021</th>\n",
       "      <th>Q022</th>\n",
       "      <th>Q023</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "      <th>Q026</th>\n",
       "      <th>Q027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170003336736</td>\n",
       "      <td>2017</td>\n",
       "      <td>3503208</td>\n",
       "      <td>Araraquara</td>\n",
       "      <td>35</td>\n",
       "      <td>SP</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170003333545</td>\n",
       "      <td>2017</td>\n",
       "      <td>5002902</td>\n",
       "      <td>CassilΓndia</td>\n",
       "      <td>50</td>\n",
       "      <td>MS</td>\n",
       "      <td>22.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170001663644</td>\n",
       "      <td>2017</td>\n",
       "      <td>3550308</td>\n",
       "      <td>Sπo Paulo</td>\n",
       "      <td>35</td>\n",
       "      <td>SP</td>\n",
       "      <td>38.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170001663645</td>\n",
       "      <td>2017</td>\n",
       "      <td>4209300</td>\n",
       "      <td>Lages</td>\n",
       "      <td>42</td>\n",
       "      <td>SC</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170001663646</td>\n",
       "      <td>2017</td>\n",
       "      <td>2704302</td>\n",
       "      <td>Macei≤</td>\n",
       "      <td>27</td>\n",
       "      <td>AL</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_INSCRICAO  NU_ANO  CO_MUNICIPIO_RESIDENCIA NO_MUNICIPIO_RESIDENCIA  \\\n",
       "0  170003336736    2017                  3503208              Araraquara   \n",
       "1  170003333545    2017                  5002902             CassilΓndia   \n",
       "2  170001663644    2017                  3550308               Sπo Paulo   \n",
       "3  170001663645    2017                  4209300                   Lages   \n",
       "4  170001663646    2017                  2704302                  Macei≤   \n",
       "\n",
       "   CO_UF_RESIDENCIA SG_UF_RESIDENCIA  NU_IDADE TP_SEXO  TP_ESTADO_CIVIL  \\\n",
       "0                35               SP      29.0       F              0.0   \n",
       "1                50               MS      22.0       F              0.0   \n",
       "2                35               SP      38.0       F              0.0   \n",
       "3                42               SC      35.0       F              0.0   \n",
       "4                27               AL      40.0       M              0.0   \n",
       "\n",
       "   TP_COR_RACA  ...  Q018  Q019 Q020  Q021 Q022  Q023  Q024  Q025  Q026  Q027  \n",
       "0            1  ...     A     C    B     B    C     B     B     B     A     A  \n",
       "1            1  ...     A     B    A     A    C     B     A     A     A     A  \n",
       "2            1  ...     A     B    A     A    C     A     B     B     A     A  \n",
       "3            1  ...     B     C    A     B    D     A     B     B     A     A  \n",
       "4            3  ...     A     B    B     A    C     A     C     B     A     A  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data -- esse comando vai demorar um pouco por causa do tamanho dos dados.\n",
    "filepath = '../data/Microdados ENEM 2017/DADOS/MICRODADOS_ENEM_2017.csv' # data path -- CHANGE to match where your data is saved.\n",
    "df = pd.read_csv(filepath,encoding='cp860',sep=';', nrows=500000)        # load first 250k rows of the data and fix encoding\n",
    "# df = pd.read_csv(filepath,encoding='cp860',sep=';', nrows=250000)      # load the entire dataset.\n",
    "\n",
    "df.head()  # print the first five lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver quais são os atributos do nosso dataset. Uma explicação dos atributos pode ser encontrada na pasta `Dicionário` onde os dados form baixados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: (500000, 137)\n",
      "['NU_INSCRICAO', 'NU_ANO', 'CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'CO_MUNICIPIO_NASCIMENTO', 'NO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'SG_UF_NASCIMENTO', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO', 'CO_ESCOLA', 'CO_MUNICIPIO_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA', 'IN_DEFICIENCIA_FISICA', 'IN_DEFICIENCIA_MENTAL', 'IN_DEFICIT_ATENCAO', 'IN_DISLEXIA', 'IN_DISCALCULIA', 'IN_AUTISMO', 'IN_VISAO_MONOCULAR', 'IN_OUTRA_DEF', 'IN_GESTANTE', 'IN_LACTANTE', 'IN_IDOSO', 'IN_ESTUDA_CLASSE_HOSPITALAR', 'IN_SEM_RECURSO', 'IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_ACESSO', 'IN_TRANSCRICAO', 'IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_GUIA_INTERPRETE', 'IN_COMPUTADOR', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_PROVA_DEITADO', 'IN_MOBILIARIO_OBESO', 'IN_LAMINA_OVERLAY', 'IN_PROTETOR_AURICULAR', 'IN_MEDIDOR_GLICOSE', 'IN_MAQUINA_BRAILE', 'IN_SOROBAN', 'IN_MARCA_PASSO', 'IN_SONDA', 'IN_MEDICAMENTOS', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO', 'IN_NOME_SOCIAL', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TP_LINGUA', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', 'TX_GABARITO_MT', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025', 'Q026', 'Q027']\n"
     ]
    }
   ],
   "source": [
    "print('Size of dataset: ' + str(df.shape ))\n",
    "print(list(df))  # print feature list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset do enem tem vários atributos (uma descrição pode ser encontrada na pasta onde os dados foram baixados). Os próximos comandos reduzem o dataset retirando, por exemplo, os treineiros e indivíduos que faltaram à prova ou foram eliminados/desqualificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the dataset:(350162, 132)\n"
     ]
    }
   ],
   "source": [
    "# Remove all entries that were absent or were eliminated in at least one exam\n",
    "ix = ~df[['TP_PRESENCA_CN','TP_PRESENCA_CH','TP_PRESENCA_LC','TP_PRESENCA_MT']].applymap(lambda x: False if x==1.0 else True).any(axis=1)\n",
    "df = df.loc[ix,:]\n",
    "\n",
    "\n",
    "# Remove \"treineiros\" -- these are individuals that marked that they are taking the exam \"only to test their knowledge\". \n",
    "# It is not uncommon for students to take the ENEM in the middle of high school as a dry run\n",
    "df = df.loc[df['IN_TREINEIRO']==0,:]\n",
    "\n",
    "# drop eliminated features\n",
    "df.drop(['TP_PRESENCA_CN','TP_PRESENCA_CH','TP_PRESENCA_LC','TP_PRESENCA_MT','IN_TREINEIRO'],axis=1, inplace=True)\n",
    "\n",
    "# subsitute race by names\n",
    "features = ['N/A', 'Branca','Preta','Parda','Amarela','Indigena']\n",
    "df['TP_COR_RACA'] = df.loc[:,['TP_COR_RACA']].applymap(lambda x: features[x]).copy()\n",
    "\n",
    "# print new shape\n",
    "print('New shape of the dataset:' + str(df.shape))\n",
    "\n",
    "# reset index -- this commands resets the index of the dataset\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o dataset foi reduzido para menos de 300k entradas. Entradas individuais do dataset podem ser acessados através do comando `df.loc[]`. Por exemplo, vamos imprimir a nota de matemática do aluno na décima linha do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[10,'NU_NOTA_MT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dataframe com apenas uma coluna em `pandas` se chama um `Series`. Vamos imprimir uma série composta apenas das notas de matemática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         465.5\n",
       "1         591.2\n",
       "2         584.6\n",
       "3         578.5\n",
       "4         607.5\n",
       "5         479.0\n",
       "6         656.5\n",
       "7         430.1\n",
       "8         645.1\n",
       "9         517.6\n",
       "10        795.0\n",
       "11        425.5\n",
       "12        430.8\n",
       "13        481.7\n",
       "14        769.1\n",
       "15        790.4\n",
       "16        535.5\n",
       "17        622.8\n",
       "18        472.9\n",
       "19        672.2\n",
       "20        696.1\n",
       "21        459.2\n",
       "22        422.4\n",
       "23        539.7\n",
       "24        439.9\n",
       "25        799.6\n",
       "26        545.0\n",
       "27        405.1\n",
       "28        873.2\n",
       "29        493.9\n",
       "          ...  \n",
       "350132    577.1\n",
       "350133    399.0\n",
       "350134    576.8\n",
       "350135    630.2\n",
       "350136    415.6\n",
       "350137    377.7\n",
       "350138    390.5\n",
       "350139    567.3\n",
       "350140    730.5\n",
       "350141    721.4\n",
       "350142    402.6\n",
       "350143    470.6\n",
       "350144    617.7\n",
       "350145    624.5\n",
       "350146    642.2\n",
       "350147    579.9\n",
       "350148    586.3\n",
       "350149    400.4\n",
       "350150    580.3\n",
       "350151    714.8\n",
       "350152    501.0\n",
       "350153    618.3\n",
       "350154    532.4\n",
       "350155    524.5\n",
       "350156    375.3\n",
       "350157    571.5\n",
       "350158    466.5\n",
       "350159    783.2\n",
       "350160    432.5\n",
       "350161    546.5\n",
       "Name: NU_NOTA_MT, Length: 350162, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NU_NOTA_MT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos facilmente calcular a nota média, mediana, e variância das notas de matemática utilizando funções já implementadas dentro do objeto df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota média: 534.7401696928665\n",
      "Nota mediana: 521.2\n",
      "Desvio padrão: 108.43701795923563\n"
     ]
    }
   ],
   "source": [
    "avg = df['NU_NOTA_MT'].mean() # mean math score\n",
    "med = df['NU_NOTA_MT'].median()  # median math score\n",
    "std = df['NU_NOTA_MT'].std()  # std var of the math score\n",
    "\n",
    "print('Nota média: ' + str(avg))\n",
    "print('Nota mediana: ' + str(med))\n",
    "print('Desvio padrão: ' + str(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ATIVIDADE 2:** Calcule as notás médias, mínimas, e máximas em ciências humanas, ciências naturais, e línguas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entre sua resposta aqui\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos testar alumas manipulações adicionais no dataset. Para podermos analisar alunos que estão na mesma etapa educacional, vamos manter apenas os candidatos que estão concluindo o ensino médio em 2017. Esses candidatos estão (supostamente) no último ano do ensino médio. Essa etapa de pré-processamento reduz significamente o número de alunos que permanecerão no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the dataset:(131479, 132)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df.TP_ST_CONCLUSAO == 2]\n",
    "\n",
    "# remember to reset the index!\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# print new shape\n",
    "print('New shape of the dataset:' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra forma de acessar atributos individuais é usar o comando `df.NOME_DO_ATRIBUTO` onde, obviamente, `NOME_DO_ATRIBUTO` é o nome do atributo que você quer acessar. Para ilustar o seu uso, vamos calcular a quantidade de estudantes de diferentes raças. \n",
    "\n",
    "**Observação:** Estamos utilizando a categorização de raças encontrada nos dados do ENEM. Reconhecemos que essas categorias podem ser consideradas ofensivas e são ultrapassadas. Porém, para preservar a consistência dos dados, manteremos a nomenclatura originalmente encontrada nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of candidates from each ethnicity:\n",
      "---------------------\n",
      "Branca      43.556005\n",
      "Parda       40.856715\n",
      "Preta       10.847360\n",
      "Amarela      2.334213\n",
      "N/A          1.940234\n",
      "Indigena     0.465474\n",
      "Name: TP_COR_RACA, dtype: float64\n",
      "\n",
      "Total number of candidates from each ethnicity (in thousands):\n",
      "---------------------\n",
      "Branca      57.267\n",
      "Parda       53.718\n",
      "Preta       14.262\n",
      "Amarela      3.069\n",
      "N/A          2.551\n",
      "Indigena     0.612\n",
      "Name: TP_COR_RACA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of candidates from each ethnicity:')\n",
    "print('---------------------')\n",
    "print(100*df.TP_COR_RACA.value_counts()/len(df))\n",
    "\n",
    "print('\\nTotal number of candidates from each ethnicity (in thousands):')\n",
    "print('---------------------')\n",
    "print(df.TP_COR_RACA.value_counts()/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Atividade 3:** Calcule o número e percentagem de estudantes por estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete o exercício aqui.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos agrupar o dataset por estado (UF) e calcular a nota média em ciências naturais por estado. Isso é feito através do comando `groupby`, o que consideramos uma das funções mais poderosas do pacote `pandas`. Você pode ler mais sobre esse comando aqui:  \n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG_UF_RESIDENCIA\n",
      "MG    559.101746\n",
      "SC    550.631041\n",
      "PR    549.789271\n",
      "RJ    549.746506\n",
      "ES    549.717240\n",
      "DF    549.094902\n",
      "SP    546.404691\n",
      "RS    545.423227\n",
      "RN    543.308323\n",
      "PB    541.855160\n",
      "PI    541.648318\n",
      "SE    538.366271\n",
      "GO    537.033347\n",
      "PA    534.092729\n",
      "BA    533.209822\n",
      "AP    529.580077\n",
      "RR    528.093385\n",
      "MS    527.106997\n",
      "PE    525.665273\n",
      "MT    524.904547\n",
      "MA    522.053589\n",
      "TO    521.141789\n",
      "AC    519.450314\n",
      "AL    519.362816\n",
      "RO    518.073101\n",
      "CE    516.251490\n",
      "AM    504.365155\n",
      "Name: NU_NOTA_CH, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_series = df.groupby(['SG_UF_RESIDENCIA'])['NU_NOTA_CH'].mean()  # calcular a média por estado\n",
    "mean_series.sort_values(inplace=True,ascending=False)                # ordenar a série\n",
    "print(mean_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ATIVIDADE 4:** Imprima o nome e estado dos munícipios de onde vieram as dez maiores notas de matemática no nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ATIVIDADE 5:** Encontre a nota média em ciências humanas agrupando por raça e gênero.\n",
    "\n",
    "Note que você vai precisar agrupar o dataset por dois atributos ao invés de um -- leia a documentação/guias para aprender como fazer isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código aqui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
